{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b0d57-e571-4334-9467-b4bd44be01f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2873825a-f15a-4e4b-a2c8-aee18c9ec7b1",
   "metadata": {},
   "source": [
    "# 1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c97a28-72f6-487f-bc36-9e4cfa5ea89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lfw_dataset(min_faces_per_person=50, resize=0.5):\n",
    "    lfw_people = fetch_lfw_people(min_faces_per_person=min_faces_per_person, resize=resize)\n",
    "    X = lfw_people.data\n",
    "    y = lfw_people.target\n",
    "    target_names = lfw_people.target_names\n",
    "    n_classes = target_names.shape[0]\n",
    "    \n",
    "    print(f\"Dataset dimensions: {X.shape}\")\n",
    "    print(f\"Number of classes: {n_classes}\")\n",
    "    \n",
    "    return X, y, target_names, n_classes\n",
    "\n",
    "X, y, target_names, n_classes = load_lfw_dataset()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84f97463-9df7-4fd4-b7d0-ae2906a12a05",
   "metadata": {},
   "source": [
    "# 2. Apply PCA and split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9db340e-ffbe-47ee-9e20-4a3d8818d690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_split_data(X, y, n_components=200, test_size=0.3, random_state=42):\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=n_components, whiten=True, random_state=random_state)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, pca\n",
    "\n",
    "X_train, X_test, y_train, y_test, pca = preprocess_and_split_data(X, y)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e413f0cc-085b-48ab-9e0e-eb3bbb8febf7",
   "metadata": {},
   "source": [
    "# 3. Implement SVM classifiers with various kernels and fine-tune using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec739faf-453a-464c-80f4-ed976bcc3ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_svm(X_train, X_test, y_train, y_test, kernel, param_grid):\n",
    "    svm = SVC(kernel=kernel)\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    print(f\"\\nBest parameters for {kernel} kernel:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Define parameter grids for each kernel\n",
    "param_grids = {\n",
    "    'linear': {'C': [0.1, 1, 10, 100]},\n",
    "    'rbf': {'C': [0.1, 1, 10, 100], 'gamma': ['scale', 'auto', 0.1, 1]},\n",
    "    'poly': {'C': [0.1, 1, 10], 'degree': [2, 3, 4], 'gamma': ['scale', 'auto']}\n",
    "}\n",
    "\n",
    "# Train and evaluate SVM with different kernels\n",
    "best_models = {}\n",
    "for kernel in ['linear', 'rbf', 'poly']:\n",
    "    print(f\"\\nTraining SVM with {kernel} kernel\")\n",
    "    best_models[kernel] = train_and_evaluate_svm(X_train, X_test, y_train, y_test, kernel, param_grids[kernel])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "645257ba-af47-47fa-a62d-3ec39c0009ec",
   "metadata": {},
   "source": [
    "# 4. Plot decision boundaries and print support vectors for each best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b4c3d9-1901-407c-b3d9-d9d5843022c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(X, y, model, kernel):\n",
    "    # We'll plot the decision boundary for the first two principal components\n",
    "    X_plot = X[:, :2]\n",
    "    \n",
    "    x_min, x_max = X_plot[:, 0].min() - 1, X_plot[:, 0].max() + 1\n",
    "    y_min, y_max = X_plot[:, 1].min() - 1, X_plot[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, (x_max - x_min) / 100),\n",
    "                         np.arange(y_min, y_max, (y_max - y_min) / 100))\n",
    "    \n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.RdYlBu)\n",
    "    plt.scatter(X_plot[:, 0], X_plot[:, 1], c=y, cmap=plt.cm.RdYlBu, edgecolor='black')\n",
    "    plt.xlabel('First Principal Component')\n",
    "    plt.ylabel('Second Principal Component')\n",
    "    plt.title(f'Decision Boundary with {kernel.capitalize()} Kernel')\n",
    "    \n",
    "    # Plot support vectors\n",
    "    if hasattr(model, 'support_vectors_'):\n",
    "        plt.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1], s=100, \n",
    "                    linewidth=1, facecolors='none', edgecolors='k')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print support vectors and margin size\n",
    "    if hasattr(model, 'support_vectors_'):\n",
    "        print(f\"\\nNumber of support vectors: {model.n_support_}\")\n",
    "        print(f\"Support vectors:\\n{model.support_vectors_}\")\n",
    "        \n",
    "        # Calculate margin size for linear kernel\n",
    "        if kernel == 'linear':\n",
    "            w = model.coef_[0]\n",
    "            margin = 2 / np.sqrt(np.sum(w ** 2))\n",
    "            print(f\"\\nMargin size: {margin}\")\n",
    "    else:\n",
    "        print(\"\\nThis model does not have support vectors.\")\n",
    "\n",
    "# Plot decision boundaries and print support vectors for each best model\n",
    "for kernel, model in best_models.items():\n",
    "    plot_decision_boundary(X_train, y_train, model, kernel)\n",
    "\n",
    "# Visualize some example predictions\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "def title(y_pred, y_test, target_names, i):\n",
    "    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
    "    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
    "    return f'predicted: {pred_name}\\ntrue: {true_name}'\n",
    "\n",
    "# Choose the best model (you can change this to any of the trained models)\n",
    "best_model = best_models['rbf']\n",
    "\n",
    "prediction_titles = [title(best_model.predict(X_test), y_test, target_names, i)\n",
    "                     for i in range(y_test.shape[0])]\n",
    "\n",
    "plot_gallery(X_test, prediction_titles, h=50, w=37, n_row=3, n_col=4)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
